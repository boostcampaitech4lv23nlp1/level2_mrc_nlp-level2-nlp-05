model_args:
  model_name_or_path: 'klue/bert-base'
  dense_train_model_name: 'klue/bert-base' # DPR Encoder model name 추가
  p_encoder_path: './retriever/saved_models/p_encoder'
  q_encoder_path: './retriever/saved_models/q_encoder'
  indexer_path: './retriever/dpr_model/faiss_clusters64_29-23-52.index'
  config_name: 
  tokenizer_name:

data_args:
  dataset_name: './dataset/train_dataset'
  train_dataset_name: './dataset/train_dataset/train'
  valid_dataset_name: './dataset/train_dataset/validation'
  overwrite_cache: False
  preprocessing_num_workers:
  max_seq_length: 384
  pad_to_max_length: False
  doc_stride: 128
  max_answer_length: 30
  eval_retrieval: True
  num_clusters: 64
  top_k_retrieval: 10
  retriever_type: 'faiss'  # base, faiss, elastic
  #use_faiss : False

# DPR model training args
# lr, batch_size, epochs, weight_decay, gradient
training_args:
  output_dir: './models'
  logging_dir: './logs'
  learning_rate: 2e-5
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  num_train_epochs : 10
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  warmup_ratio : 0.1

  save_total_limit : 2
  load_best_model_at_end : True
  eval_steps : 250
  evaluation_strategy : 'steps'
  overwrite_output_dir : True
  do_train : True
  do_eval : False # 이거 근데 False라고 박아놧는데 자꾸 True로 들어감.. 왜일까
  do_predict : False

  p_encoder_save_name : 'test'
  q_encoder_save_name : 'test'

  in_batch_neg : True
  num_neg : 3 # 2^n - 1
  hard_neg : False


        